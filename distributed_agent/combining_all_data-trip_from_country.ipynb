{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pyodbc\n",
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D://code//data//data_SA_north//all.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taian = pd.read_csv('D://code//data//data_SA_north//Taian.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ENTRY_TIME'] = pd.to_datetime(df['ENTRY_TIME'],infer_datetime_format=True)\n",
    "df['EXIT_TIME'] = pd.to_datetime(df['EXIT_TIME'],infer_datetime_format=True)\n",
    "df['O_TIME'] = pd.to_datetime(df['O_TIME'],infer_datetime_format=True)\n",
    "df['D_TIME'] = pd.to_datetime(df['D_TIME'],infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_min = [00, 11, 21, 31, 41, 51]\n",
    "end_min = [10, 20, 30, 40, 50, 59]\n",
    "directions = ['N', 'S']\n",
    "days = [21, 22, 23, 24, 25, 26, 27]\n",
    "categories = [31, 32, 41, 42, 5]\n",
    "hours = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23]\n",
    "small_car = [31, 32]\n",
    "big_car = [42, 5]\n",
    "big_41 = [41]\n",
    "n_cats = [small_car, big_41, big_car]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnty_cnty_df = pd.read_excel('C://Users//AthenaLee//Documents//code//data//data_SA//GATRY_CITY.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnty_df = pd.read_csv('C://Users//AthenaLee//Documents//code//data//data_SA//GANTRY_NAME.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_clean_gantry(x):\n",
    "    x = x.strip()\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnty_cnty_df ['GANTRY_ID'] = gnty_cnty_df ['GANTRY_ID'].apply(make_clean_gantry)\n",
    "gnty_cnty_df ['CODE_NAME'] = gnty_cnty_df ['CODE_NAME'].apply(make_clean_gantry)\n",
    "gnty_df['GANTRY_ID'] = gnty_df['GANTRY_ID'].apply(make_clean_gantry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['in_location'] = df['O_CITY'].apply(define_gantry_location_in)\n",
    "df['out_location'] = df['D_CITY'].apply(define_gantry_location_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_gantry_in(x) :\n",
    "    var = x.split('-')[0]\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_gantry_out(x) :\n",
    "    var = x.split('-')[1]\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnty_df['GANTRY_ID'] = gnty_df['GANTRY_ID'].apply(make_clean_gantry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnty_df[\"in\"] = gnty_df['GANTRY_NAME'].apply(split_gantry_in)\n",
    "gnty_df[\"out\"] = gnty_df['GANTRY_NAME'].apply(split_gantry_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each SA df, apply to [\"O_CITY\"]\n",
    "def define_gantry_location_in(x):\n",
    "    #location = ''\n",
    "    for index, gantry in enumerate(gnty_df['GANTRY_ID']):\n",
    "        if x == gantry :\n",
    "            location = gnty_df.iloc[index, :]['in']\n",
    "    return location        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each SA df, apply to [\"D_CITY\"]\n",
    "def define_gantry_location_out(x):\n",
    "    #location = ''\n",
    "    for index, gantry in enumerate(gnty_df['GANTRY_ID']):\n",
    "        if x == gantry :\n",
    "            location = gnty_df.iloc[index, :]['out']\n",
    "    return location     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each SA df, apply to [\"O_CITY\"]\n",
    "def define_gantry_location_country(x):\n",
    "    #location = ''\n",
    "    for index, gantry in enumerate(gnty_cnty_df ['GANTRY_ID']):\n",
    "        if x == gantry :\n",
    "            location = gnty_cnty_df.iloc[index, :]['CODE_NAME']\n",
    "    return location        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_taian['O_COUNTRY'] = df_taian['O_CITY'].apply(define_gantry_location_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['in_location'] = df['O_CITY'].apply(define_gantry_location_in)\n",
    "df['out_location'] = df['D_CITY'].apply(define_gantry_location_out)\n",
    "df['O_COUNTRY'] = df['O_CITY'].apply(define_gantry_location_country)\n",
    "df['D_COUNTRY'] = df['D_CITY'].apply(define_gantry_location_country)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('D://code//data//data_SA_north//all_wOD.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combine all data with OD country and OD gateway, then insert into SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest\n",
    "engine = create_engine('mssql://ATHENALEE-PC\\\\SQLEXPRESS/athena_dev?driver=SQL+Server?trusted_connection=yes') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taian : done loading data ...\n",
      "Taian : done formating time columns ...\n",
      "Taian : done OD columns <in_location> ...\n",
      "Taian : done OD columns <out_location> ...\n",
      "Taian : done OD columns <O_COUNTRY> ...\n",
      "Taian : done OD columns <D_COUNTRY> ...\n",
      "Taian : done ! ...\n",
      "Zhongli : done loading data ...\n",
      "Zhongli : done formating time columns ...\n",
      "Zhongli : done OD columns <in_location> ...\n",
      "Zhongli : done OD columns <out_location> ...\n",
      "Zhongli : done OD columns <O_COUNTRY> ...\n",
      "Zhongli : done OD columns <D_COUNTRY> ...\n",
      "Zhongli : done ! ...\n",
      "Xihu : done loading data ...\n",
      "Xihu : done formating time columns ...\n",
      "Xihu : done OD columns <in_location> ...\n",
      "Xihu : done OD columns <out_location> ...\n",
      "Xihu : done OD columns <O_COUNTRY> ...\n",
      "Xihu : done OD columns <D_COUNTRY> ...\n",
      "Xihu : done ! ...\n",
      "Xilou : done loading data ...\n",
      "Xilou : done formating time columns ...\n",
      "Xilou : done OD columns <in_location> ...\n",
      "Xilou : done OD columns <out_location> ...\n",
      "Xilou : done OD columns <O_COUNTRY> ...\n",
      "Xilou : done OD columns <D_COUNTRY> ...\n",
      "Xilou : done ! ...\n",
      "Nantou : done loading data ...\n",
      "Nantou : done formating time columns ...\n",
      "Nantou : done OD columns <in_location> ...\n",
      "Nantou : done OD columns <out_location> ...\n",
      "Nantou : done OD columns <O_COUNTRY> ...\n",
      "Nantou : done OD columns <D_COUNTRY> ...\n",
      "Nantou : done ! ...\n",
      "QingShui : done loading data ...\n",
      "QingShui : done formating time columns ...\n",
      "QingShui : done OD columns <in_location> ...\n",
      "QingShui : done OD columns <out_location> ...\n",
      "QingShui : done OD columns <O_COUNTRY> ...\n",
      "QingShui : done OD columns <D_COUNTRY> ...\n",
      "QingShui : done ! ...\n",
      "Huko : done loading data ...\n",
      "Huko : done formating time columns ...\n",
      "Huko : done OD columns <in_location> ...\n",
      "Huko : done OD columns <out_location> ...\n",
      "Huko : done OD columns <O_COUNTRY> ...\n",
      "Huko : done OD columns <D_COUNTRY> ...\n",
      "Huko : done ! ...\n",
      "Guanxi : done loading data ...\n",
      "Guanxi : done formating time columns ...\n",
      "Guanxi : done OD columns <in_location> ...\n",
      "Guanxi : done OD columns <out_location> ...\n",
      "Guanxi : done OD columns <O_COUNTRY> ...\n",
      "Guanxi : done OD columns <D_COUNTRY> ...\n",
      "Guanxi : done ! ...\n",
      "=========== done concat ! ===========\n",
      "inserted successfully !\n"
     ]
    }
   ],
   "source": [
    "SA_name = [\"Taian\", \"Zhongli\", \"Xihu\", \"Xilou\", \"Nantou\", \"QingShui\", \"Huko\", \"Guanxi\"]\n",
    "df_dicts = {}\n",
    "df_lists = []\n",
    "for sa in SA_name :\n",
    "    if sa == \"Zhongli\" :\n",
    "        df_N = pd.read_csv('C://Users//AthenaLee//Documents//code//data//data_SA//Zhongli_N.csv', low_memory=False)\n",
    "        df_S = pd.read_csv('C://Users//AthenaLee//Documents//code//data//data_SA//Zhongli_S.csv', low_memory=False)\n",
    "        df = df = pd.concat([df_N, df_S])       \n",
    "    else :\n",
    "        df = pd.read_csv('C://Users//AthenaLee//Documents//code//data//data_SA//{0}.csv'.format(sa), low_memory=False)\n",
    "    print(\"{0} : done loading data ...\".format(sa))\n",
    "    \n",
    "    df['ENTRY_TIME'] = pd.to_datetime(df['ENTRY_TIME'],infer_datetime_format=True)\n",
    "    df['EXIT_TIME'] = pd.to_datetime(df['EXIT_TIME'],infer_datetime_format=True)\n",
    "    df['O_TIME'] = pd.to_datetime(df['O_TIME'],infer_datetime_format=True)\n",
    "    df['D_TIME'] = pd.to_datetime(df['D_TIME'],infer_datetime_format=True)\n",
    "    print(\"{0} : done formating time columns ...\".format(sa))\n",
    "    \n",
    "    df['in_location'] = df['O_CITY'].apply(define_gantry_location_in)\n",
    "    print(\"{0} : done OD columns <in_location> ...\".format(sa))\n",
    "    df['out_location'] = df['D_CITY'].apply(define_gantry_location_out)\n",
    "    print(\"{0} : done OD columns <out_location> ...\".format(sa))\n",
    "    df['O_COUNTRY'] = df['O_CITY'].apply(define_gantry_location_country)\n",
    "    print(\"{0} : done OD columns <O_COUNTRY> ...\".format(sa))\n",
    "    df['D_COUNTRY'] = df['D_CITY'].apply(define_gantry_location_country)\n",
    "    print(\"{0} : done OD columns <D_COUNTRY> ...\".format(sa))\n",
    "    \n",
    "    df_dicts['{0}_df'.format(sa)] = df\n",
    "    df_lists.append(df_dicts['{0}_df'.format(sa)])\n",
    "    print(\"{0} : done ! ...\".format(sa))\n",
    "final_df = pd.concat(df_lists)\n",
    "print('=========== done concat ! ===========')\n",
    "final_df.to_sql(\"all_wOD\", engine, if_exists='replace', chunksize=50)\n",
    "print('inserted successfully !')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.to_csv('C://Users//AthenaLee//Documents//code//data//data_SA//all_wOD.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46.68194444444444"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "16726.674238204956/60/60\n",
    "168055/60/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---bms calculation : 16727.963806152344 seconds ---\n",
      "done calculation !\n",
      "---泰安 category 31 : 16747.52889752388 seconds ---\n",
      "done 泰安 31 file\n",
      "---bms calculation : 4673.592910528183 seconds ---\n",
      "done calculation !\n",
      "---泰安 category 32 : 4692.383670806885 seconds ---\n",
      "done 泰安 32 file\n",
      "---bms calculation : 1149.0032329559326 seconds ---\n",
      "done calculation !\n",
      "---泰安 category 41 : 1165.1064653396606 seconds ---\n",
      "done 泰安 41 file\n",
      "---bms calculation : 1204.7235004901886 seconds ---\n",
      "done calculation !\n",
      "---泰安 category 42 : 1221.292324066162 seconds ---\n",
      "done 泰安 42 file\n",
      "---bms calculation : 801.8024010658264 seconds ---\n",
      "done calculation !\n",
      "---泰安 category 5 : 817.7492694854736 seconds ---\n",
      "done 泰安 5 file\n",
      "---bms calculation : 5580.434569597244 seconds ---\n",
      "done calculation !\n",
      "---中壢 category 31 : 5598.810527801514 seconds ---\n",
      "done 中壢 31 file\n",
      "---bms calculation : 2006.5927443504333 seconds ---\n",
      "done calculation !\n",
      "---中壢 category 32 : 2021.7653274536133 seconds ---\n",
      "done 中壢 32 file\n",
      "---bms calculation : 422.2356231212616 seconds ---\n",
      "done calculation !\n",
      "---中壢 category 41 : 435.9995551109314 seconds ---\n",
      "done 中壢 41 file\n",
      "---bms calculation : 923.2028946876526 seconds ---\n",
      "done calculation !\n",
      "---中壢 category 42 : 937.516126871109 seconds ---\n",
      "done 中壢 42 file\n",
      "---bms calculation : 376.9530510902405 seconds ---\n",
      "done calculation !\n",
      "---中壢 category 5 : 389.6242640018463 seconds ---\n",
      "done 中壢 5 file\n",
      "---bms calculation : 11614.595488786697 seconds ---\n",
      "done calculation !\n",
      "---西湖 category 31 : 11632.515574455261 seconds ---\n",
      "done 西湖 31 file\n",
      "---bms calculation : 3517.2672352790833 seconds ---\n",
      "done calculation !\n",
      "---西湖 category 32 : 3534.9998276233673 seconds ---\n",
      "done 西湖 32 file\n",
      "---bms calculation : 671.8288037776947 seconds ---\n",
      "done calculation !\n",
      "---西湖 category 41 : 687.8128492832184 seconds ---\n",
      "done 西湖 41 file\n",
      "---bms calculation : 977.3343269824982 seconds ---\n",
      "done calculation !\n",
      "---西湖 category 42 : 993.6408586502075 seconds ---\n",
      "done 西湖 42 file\n",
      "---bms calculation : 1409.9682228565216 seconds ---\n",
      "done calculation !\n",
      "---西湖 category 5 : 1426.094703912735 seconds ---\n",
      "done 西湖 5 file\n",
      "---bms calculation : 10380.56123828888 seconds ---\n",
      "done calculation !\n",
      "---西螺 category 31 : 10398.405559062958 seconds ---\n",
      "done 西螺 31 file\n",
      "---bms calculation : 3462.73096370697 seconds ---\n",
      "done calculation !\n",
      "---西螺 category 32 : 3479.3902847766876 seconds ---\n",
      "done 西螺 32 file\n",
      "---bms calculation : 779.6560554504395 seconds ---\n",
      "done calculation !\n",
      "---西螺 category 41 : 795.2973608970642 seconds ---\n",
      "done 西螺 41 file\n",
      "---bms calculation : 1400.1349244117737 seconds ---\n",
      "done calculation !\n",
      "---西螺 category 42 : 1416.3277909755707 seconds ---\n",
      "done 西螺 42 file\n",
      "---bms calculation : 988.7037222385406 seconds ---\n",
      "done calculation !\n",
      "---西螺 category 5 : 1004.1094033718109 seconds ---\n",
      "done 西螺 5 file\n",
      "---bms calculation : 7847.666376590729 seconds ---\n",
      "done calculation !\n",
      "---南投 category 31 : 7864.71892786026 seconds ---\n",
      "done 南投 31 file\n",
      "---bms calculation : 2247.218216896057 seconds ---\n",
      "done calculation !\n",
      "---南投 category 32 : 2263.4842331409454 seconds ---\n",
      "done 南投 32 file\n",
      "---bms calculation : 530.8855473995209 seconds ---\n",
      "done calculation !\n",
      "---南投 category 41 : 544.9685821533203 seconds ---\n",
      "done 南投 41 file\n",
      "---bms calculation : 302.9538061618805 seconds ---\n",
      "done calculation !\n",
      "---南投 category 42 : 314.32781624794006 seconds ---\n",
      "done 南投 42 file\n",
      "---bms calculation : 95.26902198791504 seconds ---\n",
      "done calculation !\n",
      "---南投 category 5 : 106.15842485427856 seconds ---\n",
      "done 南投 5 file\n",
      "---bms calculation : 12790.406664848328 seconds ---\n",
      "done calculation !\n",
      "---清水 category 31 : 12810.5039935112 seconds ---\n",
      "done 清水 31 file\n",
      "---bms calculation : 3744.5658252239227 seconds ---\n",
      "done calculation !\n",
      "---清水 category 32 : 3762.1440105438232 seconds ---\n",
      "done 清水 32 file\n",
      "---bms calculation : 752.781492471695 seconds ---\n",
      "done calculation !\n",
      "---清水 category 41 : 768.3019199371338 seconds ---\n",
      "done 清水 41 file\n",
      "---bms calculation : 713.6720101833344 seconds ---\n",
      "done calculation !\n",
      "---清水 category 42 : 729.5684027671814 seconds ---\n",
      "done 清水 42 file\n",
      "---bms calculation : 440.3094091415405 seconds ---\n",
      "done calculation !\n",
      "---清水 category 5 : 454.6413199901581 seconds ---\n",
      "done 清水 5 file\n",
      "---bms calculation : 29285.78491640091 seconds ---\n",
      "done calculation !\n",
      "---湖口 category 31 : 29304.797019720078 seconds ---\n",
      "done 湖口 31 file\n",
      "---bms calculation : 8536.738977909088 seconds ---\n",
      "done calculation !\n",
      "---湖口 category 32 : 8554.388221263885 seconds ---\n",
      "done 湖口 32 file\n",
      "---bms calculation : 2014.5084619522095 seconds ---\n",
      "done calculation !\n",
      "---湖口 category 41 : 2032.1153111457825 seconds ---\n",
      "done 湖口 41 file\n",
      "---bms calculation : 2400.603191614151 seconds ---\n",
      "done calculation !\n",
      "---湖口 category 42 : 2417.3550341129303 seconds ---\n",
      "done 湖口 42 file\n",
      "---bms calculation : 1803.4436333179474 seconds ---\n",
      "done calculation !\n",
      "---湖口 category 5 : 1820.15584897995 seconds ---\n",
      "done 湖口 5 file\n",
      "---bms calculation : 16351.17119050026 seconds ---\n",
      "done calculation !\n",
      "---關西 category 31 : 16368.91551733017 seconds ---\n",
      "done 關西 31 file\n",
      "---bms calculation : 4640.445329427719 seconds ---\n",
      "done calculation !\n",
      "---關西 category 32 : 4657.541867733002 seconds ---\n",
      "done 關西 32 file\n",
      "---bms calculation : 1287.1521110534668 seconds ---\n",
      "done calculation !\n",
      "---關西 category 41 : 1303.9853768348694 seconds ---\n",
      "done 關西 41 file\n",
      "---bms calculation : 1215.3235421180725 seconds ---\n",
      "done calculation !\n",
      "---關西 category 42 : 1231.438797235489 seconds ---\n",
      "done 關西 42 file\n",
      "---bms calculation : 1334.3135035037994 seconds ---\n",
      "done calculation !\n",
      "---關西 category 5 : 1349.4977991580963 seconds ---\n",
      "done 關西 5 file\n",
      "---query time : 168055.38101172447 seconds ---\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time_out = time.time()\n",
    "sorting_trip(final_df)\n",
    "print(\"---query time : %s seconds ---\" % (time.time() - start_time_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sorting_trip(df) :\n",
    "    SA_name = [\"Taian\", \"Zhongli\", \"Xihu\", \"Xilou\", \"Nantou\", \"QingShui\", \"Huko\", \"Guanxi\"]\n",
    "    SA_Cname = ['泰安', '中壢', '西湖', '西螺', '南投', '清水', '湖口', '關西']\n",
    "    categories = [31, 32, 41, 42, 5]\n",
    "    for idx, sa in enumerate(SA_Cname) :  # the first SA\n",
    "        #writer = pd.ExcelWriter('C://Users//Administrator//Documents//code//data//SA_advanced//analysis_result//{0}_{1}_all_trip.xlsx'.format(sa, category))\n",
    "        categories_df = {}\n",
    "        \n",
    "        for category in categories :\n",
    "            start_time = time.time()\n",
    "            #writer = pd.ExcelWriter('C://Users//Administrator//Documents//code//data//SA_advanced//analysis_result//{0}_{1}_all_trip.xlsx'.format(sa, category))\n",
    "            var_dict = {}\n",
    "            cnt_row = []\n",
    "            for var in SA_Cname :\n",
    "                var_dict['v_{0}'.format(var)] = 0\n",
    "            \n",
    "            unique_bms = df[(df.SERVICE_AREA == sa)&(df.STOP == 'P')&(df.MVDIS_CATEGORY == category)]['BMS_TX_BATCH'].unique()\n",
    "            \n",
    "            first_row = []\n",
    "            second_row = []\n",
    "            third_row = []\n",
    "            col_name = []\n",
    "            \n",
    "            for bms in unique_bms :\n",
    "                series = df[(df.BMS_TX_BATCH == bms)&(df.STOP == 'P')].groupby(\"SERVICE_AREA\").size()\n",
    "                cnt_df = pd.DataFrame(series).reset_index()\n",
    "                length = cnt_df.shape[0]\n",
    "                for p_name in [x for index, x in enumerate(SA_Cname) if index != idx] : # this list won't have the first SA itself \n",
    "                    for idx_cnt, i in cnt_df.iterrows():\n",
    "                        if i.SERVICE_AREA == p_name :\n",
    "                            var_dict[\"v_{0}\".format(p_name)] = var_dict[\"v_{0}\".format(p_name)] + i[0]\n",
    "            print(\"---bms calculation : %s seconds ---\" % (time.time() - start_time))\n",
    "            print('done calculation !')\n",
    "            # trip grouping start here\n",
    "            #bms_df = df[(df.BMS_TX_BATCH.isin(unique_bms))]\n",
    "            for sa2 in [x for index, x in enumerate(SA_Cname) if index != idx] : # sa2 should be the same with p_name\n",
    "                col_name.append(sa2)\n",
    "                select_vID = df[(df.BMS_TX_BATCH.isin(unique_bms))&(df.SERVICE_AREA == sa2)&(df.STOP == 'P')]['VEHICLE_ID'].unique()\n",
    "                trip_series = df[df.VEHICLE_ID.isin(select_vID)].groupby(['in_location', 'out_location']).size().sort_values(0, ascending=False)[:3]\n",
    "                trip_df = pd.DataFrame(trip_series).reset_index()\n",
    "                trip_dict = {}\n",
    "                for idx_trip, place in trip_df.iterrows():\n",
    "                    place_string = \"{0}-{1}\".format(place['in_location'], place['out_location'])\n",
    "                    trip_dict['{0}_place'.format(idx_trip)] = place_string\n",
    "                    if idx_trip == 0 :\n",
    "                        first_row.append(trip_dict['{0}_place'.format(idx_trip)])\n",
    "                    elif idx_trip == 1 :\n",
    "                        second_row.append(trip_dict['{0}_place'.format(idx_trip)])\n",
    "                    elif idx_trip == 2 :\n",
    "                        third_row.append(trip_dict['{0}_place'.format(idx_trip)])\n",
    "                # collect the variables of car counting\n",
    "                cnt_row.append(var_dict['v_{0}'.format(sa2)])\n",
    "            result_df =  pd.DataFrame([cnt_row, first_row, second_row, third_row], columns = col_name)    \n",
    "            categories_df['{0}_{1}'.format(sa, category)] = result_df\n",
    "            \n",
    "            writer = pd.ExcelWriter('C://Users//AthenaLee//Documents//code//data//data_SA//analysis_result\\ALL_TRIP_SORTING//{0}_{1}_all_trip.xlsx'.format(sa, category))\n",
    "            categories_df['{0}_{1}'.format(sa, category)].to_excel(writer,'{0}_{1}_trip'.format(sa, category)) \n",
    "            writer.save()\n",
    "            print(\"---{0} category {1} : {2} seconds ---\" .format(sa, category,(time.time() - start_time)))\n",
    "            print('done {0} {1} file'.format(sa, category))\n",
    "        # saving excel\n",
    "        #writer = pd.ExcelWriter('C://Users//Administrator//Documents//code//data//SA_advanced//analysis_result//{0}_{1}_all_trip.xlsx'.format(sa, category))\n",
    "        #writer.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SA_Cname = ['泰安']\n",
    "categories = [31, 32, 41, 42, 5]\n",
    "    for idx, sa in enumerate(SA_Cname) :  # the first SA\n",
    "        #writer = pd.ExcelWriter('C://Users//Administrator//Documents//code//data//SA_advanced//analysis_result//{0}_{1}_all_trip.xlsx'.format(sa, category))\n",
    "        categories_df = {}\n",
    "        \n",
    "        for category in categories :\n",
    "            #writer = pd.ExcelWriter('C://Users//Administrator//Documents//code//data//SA_advanced//analysis_result//{0}_{1}_all_trip.xlsx'.format(sa, category))\n",
    "            var_dict = {}\n",
    "            cnt_row = []\n",
    "            for var in SA_Cname :\n",
    "                var_dict['v_{0}'.format(var)] = 0\n",
    "            \n",
    "            unique_bms = df[(df.SERVICE_AREA == sa)&(df.STOP == 'P')&(df.MVDIS_CATEGORY == category)]['BMS_TX_BATCH'].unique()\n",
    "            \n",
    "            first_row = []\n",
    "            second_row = []\n",
    "            third_row = []\n",
    "            col_name = []\n",
    "            \n",
    "            for bms in unique_bms :\n",
    "                series = df[(df.BMS_TX_BATCH == bms)&(df.STOP == 'P')].groupby(\"SERVICE_AREA\").size()\n",
    "                cnt_df = pd.DataFrame(series).reset_index()\n",
    "                length = cnt_df.shape[0]\n",
    "                for p_name in [x for index, x in enumerate(SA_Cname) if index != idx] : # this list won't have the first SA itself \n",
    "                    for idx_cnt, i in cnt_df.iterrows():\n",
    "                        if i.SERVICE_AREA == p_name :\n",
    "                            var_dict[\"v_{0}\".format(p_name)] = var_dict[\"v_{0}\".format(p_name)] + i[0]\n",
    "            # trip grouping start here\n",
    "            #bms_df = df[(df.BMS_TX_BATCH.isin(unique_bms))]\n",
    "            for sa2 in [x for index, x in enumerate(SA_Cname) if index != idx] : # sa2 should be the same with p_name\n",
    "                col_name.append(sa2)\n",
    "                select_vID = df[(df.BMS_TX_BATCH.isin(unique_bms))&(df.SERVICE_AREA == sa2)&(df.STOP == 'P')]['VEHICLE_ID'].unique()\n",
    "                trip_series = df[df.VEHICLE_ID.isin(select_vID)].groupby(['in_location', 'out_location']).size().sort_values(0, ascending=False)[:3]\n",
    "                trip_df = pd.DataFrame(trip_series).reset_index()\n",
    "                trip_dict = {}\n",
    "                for idx_trip, place in trip_df.iterrows():\n",
    "                    place_string = \"{0}-{1}\".format(place['in_location'], place['out_location'])\n",
    "                    trip_dict['{0}_place'.format(idx_trip)] = place_string\n",
    "                    if idx_trip == 0 :\n",
    "                        first_row.append(trip_dict['{0}_place'.format(idx_trip)])\n",
    "                    elif idx_trip == 1 :\n",
    "                        second_row.append(trip_dict['{0}_place'.format(idx_trip)])\n",
    "                    elif idx_trip == 2 :\n",
    "                        third_row.append(trip_dict['{0}_place'.format(idx_trip)])\n",
    "                # collect the variables of car counting\n",
    "                cnt_row.append(var_dict['v_{0}'.format(sa2)])\n",
    "            result_df =  pd.DataFrame([cnt_row, first_row, second_row, third_row], columns = col_name)    \n",
    "            categories_df['{0}_{1}'.format(sa, category)] = result_df\n",
    "            \n",
    "            writer = pd.ExcelWriter('C://Users//Administrator//Documents//code//data//SA_advanced//analysis_result//{0}_{1}_all_trip.xlsx'.format(sa, category))\n",
    "            categories_df['{0}_{1}'.format(sa, category)].to_excel(writer,'{0}_{1}_trip'.format(sa, category)) \n",
    "            writer.save()\n",
    "        # saving excel\n",
    "        #writer = pd.ExcelWriter('C://Users//Administrator//Documents//code//data//SA_advanced//analysis_result//{0}_{1}_all_trip.xlsx'.format(sa, category))\n",
    "        #writer.save()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
